"""
RAG Utilities for Finsearcher
Handles document parsing (PDF, Text), embedding-based retrieval, and document QA.
"""
import pypdf
import io
from typing import List, Dict, Optional, Tuple
import os
import config

def parse_pdf(file_bytes: bytes) -> str:
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        pdf_reader = pypdf.PdfReader(io.BytesIO(file_bytes))
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        return f"Error parsing PDF: {str(e)}"

def parse_text(file_bytes: bytes) -> str:
    """í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        return file_bytes.decode("utf-8")
    except Exception as e:
        return f"Error parsing text: {str(e)}"

def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 100) -> List[str]:
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
    chunks = []
    start = 0
    text_len = len(text)
    
    while start < text_len:
        end = start + chunk_size
        chunks.append(text[start:end])
        start += chunk_size - overlap
        
    return chunks

def simple_retrieval(query: str, chunks: List[str], top_k: int = 3) -> List[str]:
    """
    ê°œì„ ëœ í‚¤ì›Œë“œ ë§¤ì¹­ ê¸°ë°˜ ê²€ìƒ‰
    - í•œê¸€/ì˜ì–´ í˜•íƒœì†Œ ê³ ë ¤
    - ë¶€ë¶„ ë§¤ì¹­ ì§€ì›
    - ë¬¸ì¥ ìœ ì‚¬ë„ ê³„ì‚°
    """
    if not chunks:
        return []
    
    scores = []
    query_lower = query.lower()
    
    # ì¿¼ë¦¬ í† í°í™” (ê³µë°±, ì¡°ì‚¬ ë“± ì œê±°)
    import re
    # í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ì¶”ì¶œ
    query_terms = re.findall(r'[ê°€-í£]+|[a-zA-Z]+|[0-9]+', query_lower)
    
    for chunk in chunks:
        chunk_lower = chunk.lower()
        score = 0
        
        # 1. ì •í™•í•œ ì¿¼ë¦¬ ë¬¸ìì—´ ë§¤ì¹­ (ë†’ì€ ì ìˆ˜)
        if query_lower in chunk_lower:
            score += 10
        
        # 2. ê° í† í° ë§¤ì¹­
        for term in query_terms:
            if len(term) < 2:  # ë„ˆë¬´ ì§§ì€ ë‹¨ì–´ ë¬´ì‹œ
                continue
            if term in chunk_lower:
                score += 3
            # ë¶€ë¶„ ë§¤ì¹­ (ê¸´ ë‹¨ì–´ì˜ ê²½ìš°)
            elif len(term) >= 3:
                for i in range(len(chunk_lower) - len(term) + 1):
                    if chunk_lower[i:i+len(term)] == term:
                        score += 2
                        break
        
        # 3. ë¬¸ì n-gram ìœ ì‚¬ë„ (2-gram)
        def get_ngrams(text, n=2):
            return set(text[i:i+n] for i in range(len(text)-n+1))
        
        query_ngrams = get_ngrams(query_lower)
        chunk_ngrams = get_ngrams(chunk_lower[:500])  # ì²­í¬ ì•ë¶€ë¶„ë§Œ
        
        if query_ngrams and chunk_ngrams:
            overlap = len(query_ngrams & chunk_ngrams)
            score += overlap * 0.1
        
        scores.append((score, chunk))
    
    # ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    scores.sort(key=lambda x: x[0], reverse=True)
    
    # ì ìˆ˜ê°€ 0ë³´ë‹¤ í° ê²ƒë§Œ ë°˜í™˜, ì—†ìœ¼ë©´ ìƒìœ„ ì²­í¬ ë°˜í™˜
    result = [chunk for score, chunk in scores[:top_k] if score > 0]
    
    # ë§¤ì¹­ë˜ëŠ” ê²ƒì´ ì—†ìœ¼ë©´ ìƒìœ„ ì²­í¬ë¼ë„ ë°˜í™˜
    if not result and chunks:
        result = [scores[0][1]] if scores else chunks[:top_k]
    
    return result


class DocumentStore:
    """
    ë¬¸ì„œ ì €ì¥ì†Œ í´ë˜ìŠ¤ - RAGë¥¼ ìœ„í•œ ë¬¸ì„œ ê´€ë¦¬
    """
    def __init__(self):
        self.documents: Dict[str, Dict] = {}  # filename -> {text, chunks}
    
    def add_document(self, filename: str, file_bytes: bytes) -> Tuple[bool, str]:
        """
        ë¬¸ì„œ ì¶”ê°€ (PDF ë˜ëŠ” í…ìŠ¤íŠ¸ íŒŒì¼)
        
        Args:
            filename: íŒŒì¼ëª…
            file_bytes: íŒŒì¼ ë°”ì´íŠ¸ ë°ì´í„°
        
        Returns:
            (ì„±ê³µì—¬ë¶€, ë©”ì‹œì§€)
        """
        try:
            # íŒŒì¼ í™•ì¥ìì— ë”°ë¼ íŒŒì‹±
            if filename.lower().endswith('.pdf'):
                text = parse_pdf(file_bytes)
            elif filename.lower().endswith(('.txt', '.md')):
                text = parse_text(file_bytes)
            else:
                return False, "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (PDF, TXT, MD ì§€ì›)"
            
            if text.startswith("Error"):
                return False, text
            
            # í…ìŠ¤íŠ¸ ì²­í‚¹
            chunks = chunk_text(text, chunk_size=800, overlap=100)
            
            # ì €ì¥
            self.documents[filename] = {
                "text": text,
                "chunks": chunks,
                "chunk_count": len(chunks)
            }
            
            return True, f"'{filename}' ë¬¸ì„œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ({len(chunks)}ê°œ ì²­í¬)"
        
        except Exception as e:
            return False, f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"
    
    def remove_document(self, filename: str) -> bool:
        """ë¬¸ì„œ ì œê±°"""
        if filename in self.documents:
            del self.documents[filename]
            return True
        return False
    
    def get_all_chunks(self) -> List[str]:
        """ëª¨ë“  ë¬¸ì„œì˜ ì²­í¬ ë°˜í™˜"""
        all_chunks = []
        for doc in self.documents.values():
            all_chunks.extend(doc["chunks"])
        return all_chunks
    
    def search(self, query: str, top_k: int = 5) -> List[str]:
        """ëª¨ë“  ë¬¸ì„œì—ì„œ ê²€ìƒ‰"""
        all_chunks = self.get_all_chunks()
        if not all_chunks:
            return []
        return simple_retrieval(query, all_chunks, top_k)
    
    def get_document_list(self) -> List[Dict]:
        """ë¬¸ì„œ ëª©ë¡ ë°˜í™˜"""
        return [
            {"filename": fname, "chunk_count": doc["chunk_count"]}
            for fname, doc in self.documents.items()
        ]
    
    def clear(self):
        """ëª¨ë“  ë¬¸ì„œ ì‚­ì œ"""
        self.documents.clear()


def answer_with_rag(query: str, document_store: DocumentStore, chat_history: List[Dict] = None) -> str:
    """
    RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        document_store: ë¬¸ì„œ ì €ì¥ì†Œ
        chat_history: ì´ì „ ëŒ€í™” ê¸°ë¡
    
    Returns:
        AI ì‘ë‹µ
    """
    if not config.OPENAI_API_KEY or config.OPENAI_API_KEY == "your_openai_api_key_here":
        return "âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    relevant_chunks = document_store.search(query, top_k=5)
    
    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì „ì²´ ë¬¸ì„œ ì²­í¬ ì‚¬ìš© (Fallback)
    if not relevant_chunks:
        all_chunks = document_store.get_all_chunks()
        if not all_chunks:
            return "ğŸ“š ì—…ë¡œë“œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
        # ì „ì²´ ë¬¸ì„œì˜ ì•ë¶€ë¶„ ì²­í¬ë“¤ ì‚¬ìš©
        relevant_chunks = all_chunks[:5]
    
    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context = "\n\n---\n\n".join(relevant_chunks)
    
    try:
        from langchain_openai import ChatOpenAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
        
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.3,
            api_key=config.OPENAI_API_KEY
        )
        
        system_prompt = f"""ë‹¹ì‹ ì€ íˆ¬ì ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ë¬¸ì„œì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

**ì°¸ê³  ë¬¸ì„œ ë‚´ìš©:**
{context}

**ë‹µë³€ ê°€ì´ë“œë¼ì¸:**
1. ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
2. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
3. ë‹µë³€ì€ ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
4. ê´€ë ¨ ì¸ìš©êµ¬ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì–¸ê¸‰í•˜ì„¸ìš”."""
        
        messages = [SystemMessage(content=system_prompt)]
        
        # ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶”ê°€
        if chat_history:
            for msg in chat_history[-4:]:
                if msg["role"] == "user":
                    messages.append(HumanMessage(content=msg["content"]))
                elif msg["role"] == "assistant":
                    messages.append(AIMessage(content=msg["content"]))
        
        messages.append(HumanMessage(content=query))
        
        response = llm.invoke(messages)
        return response.content
        
    except Exception as e:
        return f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


def summarize_document(document_store: DocumentStore, filename: str = None) -> str:
    """
    ë¬¸ì„œ ìš”ì•½ ìƒì„±
    
    Args:
        document_store: ë¬¸ì„œ ì €ì¥ì†Œ
        filename: íŠ¹ì • íŒŒì¼ëª… (Noneì´ë©´ ì „ì²´)
    
    Returns:
        ìš”ì•½ í…ìŠ¤íŠ¸
    """
    if not config.OPENAI_API_KEY or config.OPENAI_API_KEY == "your_openai_api_key_here":
        return "âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    if filename:
        if filename not in document_store.documents:
            return f"'{filename}' ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        text = document_store.documents[filename]["text"][:4000]  # í† í° ì œí•œ
    else:
        all_text = " ".join([doc["text"][:2000] for doc in document_store.documents.values()])
        text = all_text[:4000]
    
    if not text.strip():
        return "ìš”ì•½í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
    
    try:
        from langchain_openai import ChatOpenAI
        from langchain_core.prompts import ChatPromptTemplate
        
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.3,
            api_key=config.OPENAI_API_KEY
        )
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", "ë‹¹ì‹ ì€ ë¬¸ì„œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. íˆ¬ì ê´€ë ¨ ë¬¸ì„œë¥¼ í•µì‹¬ ë‚´ìš© ìœ„ì£¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”."),
            ("human", f"ë‹¤ìŒ ë¬¸ì„œë¥¼ 3-5ê°œì˜ í•µì‹¬ í¬ì¸íŠ¸ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{text}")
        ])
        
        response = llm.invoke(prompt.format_messages())
        return response.content
        
    except Exception as e:
        return f"âŒ ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
